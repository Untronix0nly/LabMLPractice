{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\untro\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.  5.  4.]\n",
      " [ 8.  8. 10.]\n",
      " [ 8. 15. 12.]]\n",
      "[[ 5. 11.  4.  3.  3.]\n",
      " [ 3.  9.  5.  4.  4.]\n",
      " [ 5.  8.  8. 10.  3.]\n",
      " [ 4.  8. 15. 12.  6.]\n",
      " [ 5.  5.  9.  4.  2.]]\n",
      "stride = 2\n",
      "[[[[ 9.]\n",
      "   [ 4.]]\n",
      "\n",
      "  [[ 8.]\n",
      "   [12.]]]]\n",
      "[[[[5.]\n",
      "   [4.]\n",
      "   [3.]]\n",
      "\n",
      "  [[5.]\n",
      "   [8.]\n",
      "   [3.]]\n",
      "\n",
      "  [[5.]\n",
      "   [9.]\n",
      "   [2.]]]]\n"
     ]
    }
   ],
   "source": [
    "#practice's convolution\n",
    "# test for showing how convolution is working in real life\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x_inp = tf.placeholder(tf.float32,[5,5])\n",
    "# convolution's filter\n",
    "w_inp = tf.placeholder(tf.float32,[3,3])\n",
    "# for 2D convolution in tensorflow using conv2d and input variable must have dim equal 4\n",
    "#[batch's size,length,width,channels]\n",
    "# weight must have [length,width,input channels,output channels] \n",
    "# reshaping\n",
    "#white-black\n",
    "x = tf.reshape(x_inp,[1,5,5,1])\n",
    "w = tf.reshape(w_inp,[3,3,1,1])\n",
    "\n",
    "#convolution\n",
    "#strides is a step by picture [1,N,N,1] -> with step N\n",
    "#padding = \"Valid\"  say that convolution is applied for only windows who is fully entered in massive length\n",
    "#padding = \"same\" save old dimension with using zeros into basic vector\n",
    "x_valid = tf.nn.conv2d(x,w,strides= [1,1,1,1],padding = \"VALID\")\n",
    "x_same = tf.nn.conv2d(x,w,strides = [1,1,1,1],padding = \"SAME\")\n",
    "x_valid_half = tf.nn.conv2d(x,w,strides= [1,2,2,1],padding = \"VALID\")\n",
    "x_same_half = tf.nn.conv2d(x,w,strides = [1,2,2,1],padding = \"SAME\")\n",
    "\n",
    "x = np.array([[0,1,2,1,0],\n",
    "              [4,1,0,1,0],\n",
    "              [2,0,1,1,1],\n",
    "              [1,2,3,1,0],\n",
    "              [0,4,3,2,0]])\n",
    "w = np.array([[0,1,0],\n",
    "              [1,0,1],\n",
    "              [2,1,0]])\n",
    "sess = tf.Session()\n",
    "y_valid,y_same,y_half,y_same_half = sess.run(\n",
    "                                        [x_valid,x_same,x_valid_half,x_same_half],feed_dict ={x_inp:x,w_inp:w})\n",
    "print(y_valid[0,:,:,0])\n",
    "print(y_same[0,:,:,0])\n",
    "print(\"stride = 2\")\n",
    "print(y_half)\n",
    "print(y_same_half)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding: \n",
      "[[ 4.  2.  2.]\n",
      " [ 4.  1.  1.]\n",
      " [ 2.  3.  3.]]\n",
      "Padding: strides = 2  \n",
      "[[ 4.  2.]\n",
      " [ 2.  3.]]\n"
     ]
    }
   ],
   "source": [
    "#max pooling\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "x_inp = tf.placeholder(tf.float32,[4,4])\n",
    "x = tf.reshape(x_inp,[1,4,4,1])\n",
    "x_valid = tf.nn.max_pool(x, ksize = [1,2,2,1],strides = [1,1,1,1],padding = \"VALID\")\n",
    "x_valid_h = tf.nn.max_pool(x,ksize = [1,2,2,1],strides = [1,2,2,1],padding = \"VALID\")\n",
    "\n",
    "x = np.array([[0,1,2,1],\n",
    "             [4,1,0,1],\n",
    "             [2,0,1,1],\n",
    "             [1,2,3,1]])\n",
    "sess = tf.Session()\n",
    "y_valid,y_valid_half = sess.run(\n",
    "[x_valid,x_valid_h],feed_dict={x_inp:x})\n",
    "print(\"Padding: \")\n",
    "print(y_valid[0,:,:,0])\n",
    "print(\"Padding: strides = 2  \")\n",
    "print(y_valid_half[0,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot = True)\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,784])\n",
    "y = tf.placeholder(tf.float32,[None,10])\n",
    "#gray_scale\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "w_conv_1 = tf.Variable(tf.truncated_normal([5,5,1,64],stddev = 0.1))\n",
    "\n",
    "b_conv_1 = tf.Variable(tf.constant(0.1,shape = [64]))\n",
    "conv_1 = tf.nn.conv2d(x_image,w_conv_1,strides=[1,1,1,1],padding = \"SAME\") + b_conv_1\n",
    "h_conv_1 = tf.nn.relu(conv_1)\n",
    "h_pool = tf.nn.max_pool(h_conv_1,ksize = [1,2,2,1],strides = [1,2,2,1],padding = \"SAME\")\n",
    "#h_dropout = tf.nn.dropout(h_pool,0.5)\n",
    "#second Layer\n",
    "w_conv_2 = tf.Variable(tf.truncated_normal([5,5,64,128],stddev = 0.1))\n",
    "b_conv_2 = tf.Variable(tf.constant(0.1,shape = [128]))\n",
    "\n",
    "conv_2 = tf.nn.conv2d(h_pool,w_conv_2,strides = [1,1,1,1],padding = \"SAME\") + b_conv_2\n",
    "h_conv_2 = tf.nn.relu(conv_2)\n",
    "h_pool_2 = tf.nn.max_pool(h_conv_2,ksize =[1,2,2,1],strides = [1,2,2,1],padding = \"SAME\")\n",
    "\n",
    "h_pool_2_flat = tf.reshape(h_pool_2,[-1,7*7*128])\n",
    "\n",
    "W_fc_1 = tf.Variable(tf.truncated_normal([7*7*128,1024],stddev = 0.1))\n",
    "b_fc_1 = tf.Variable(tf.constant(0.1,shape = [1024]))\n",
    "\n",
    "h_fc_1 = tf.nn.relu(tf.matmul(h_pool_2_flat,W_fc_1) + b_fc_1)\n",
    "keep_probability = tf.placeholder(tf.float32)\n",
    "h_fc_1_drop = tf.nn.dropout(h_fc_1,keep_probability)\n",
    "\n",
    "W_fc_2 = tf.Variable(tf.truncated_normal([1024,10],stddev = 0.1))\n",
    "b_fc_2 = tf.Variable(tf.constant(0.1,shape = [10]))\n",
    "logit_conv = tf.matmul(h_fc_1_drop,W_fc_2) + b_fc_2\n",
    "\n",
    "y_conv = tf.nn.softmax(logit_conv)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logit_conv,labels = y))\n",
    "train_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.arg_max(y_conv,1),tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for idx in range(100):\n",
    "    #choose 100 examples\n",
    "    batch_xs,batch_ys = mnist.train.next_batch(10)\n",
    "    sess.run(train_step,feed_dict = {x:batch_xs,y:batch_ys,keep_probability: 0.5})\n",
    "#print(sess.run(accuracy,feed_dict = {x:mnist.test.images,y:mnist.test.labels,keep_probability:0.8}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot = True)\n",
    "batch_size = 64\n",
    "latent_space = 128\n",
    "lr = 0.1\n",
    "#однослойный кодировщик\n",
    "\n",
    "ae_weight = {\n",
    "    \"encoder_w\": tf.Variable(tf.truncated_normal([784,latent_space],stddev = 0.1)),\n",
    "    \"encoder_b\":tf.Variable(tf.truncated_normal([latent_space],stddev = 0.1)),\n",
    "    \"decoder_w\":tf.Variable(tf.truncated_normal([latent_space,784],stddev = 0.1)),\n",
    "    \"decoder_b\":tf.Variable(tf.truncated_normal([784],stddev = 0.1))\n",
    "}\n",
    "\n",
    "ae_input = tf.placeholder(tf.float32,[batch_size,784])\n",
    "hidden = tf.nn.relu(tf.matmul(ae_input,ae_weight[\"encoder_w\"]) + ae_weight[\"encoder_b\"])\n",
    "visible_logits = tf.matmul(hidden,ae_weight[\"decoder_w\"]) + ae_weight[\"decoder_b\"]\n",
    "#for visualization\n",
    "visible = tf.nn.relu(visible_logits)\n",
    "ae_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = visible_logits,labels=ae_input))\n",
    "optimizer = tf.train.AdagradOptimizer(lr)\n",
    "ae_op = optimizer.minimize(ae_cost)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for idx in range(10000):\n",
    "    x_batch,_ = mnist.train.next_batch(batch_size)\n",
    "    sess.run(ae_op,feed_dict = {ae_input:x_batch})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
